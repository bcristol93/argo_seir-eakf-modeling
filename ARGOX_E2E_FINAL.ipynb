{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b1323a",
   "metadata": {},
   "source": [
    "\n",
    "# ARGOX — End‑to‑End (FINAL)  \n",
    "**Date:** 2025-11-12\n",
    "\n",
    "A streamlined notebook that runs **end‑to‑end** using **existing local cache files** (no external pulls).  \n",
    "It combines the robust loaders/plotting from **Fixed15** with early‑pipeline sanity checks from **Fixed10**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb593a",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Configuration\n",
    "Leave entries as `None` to auto-detect; set a path to override.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68de52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MOBILITY_CSV        = None\n",
    "RT_CSV              = None\n",
    "MOBILITY_VALUE_COL  = None\n",
    "\n",
    "ILI_CACHE_FILE      = None\n",
    "GT_CACHE_DIR        = None\n",
    "HUMIDITY_DAILY_CSV  = None\n",
    "\n",
    "OUT_DIR = './outputs/quicklooks'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f1f69e",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Imports & Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76568784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def _find_first_existing(candidates, search_dirs=(\".\",)):\n",
    "\n",
    "    for sd in search_dirs:\n",
    "        for c in candidates:\n",
    "            cand = os.path.join(sd, c)\n",
    "            if os.path.exists(cand):\n",
    "                return cand\n",
    "            hits = glob.glob(os.path.join(sd, '**', c), recursive=True)\n",
    "            if hits:\n",
    "                return hits[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def _case_insensitive_glob(pattern):\n",
    "    def _ci(p):\n",
    "        out=''\n",
    "        for ch in p:\n",
    "            if ch.isalpha(): out+=f'[{ch.lower()}{ch.upper()}]'\n",
    "            else: out+=ch\n",
    "        return out\n",
    "    return glob.glob(_ci(pattern), recursive=True)\n",
    "\n",
    "\n",
    "def preview(df, name, n=5):\n",
    "    if df is None:\n",
    "        print(f'[skip] {name}: not provided/not found.')\n",
    "        return\n",
    "    print(f'[preview] {name}: shape={getattr(df, \"shape\", None)}')\n",
    "    display(df.head(n))\n",
    "\n",
    "\n",
    "def week_to_season(d):\n",
    "    y = d.year\n",
    "    start = y-1 if d.month < 7 else y\n",
    "    return f\"{start}-{str(start+1)[-2:]}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95fd17a",
   "metadata": {},
   "source": [
    "\n",
    "## 2) ILI/GT/Humidity sanity (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7910f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ILI\n",
    "if ILI_CACHE_FILE is None:\n",
    "    ILI_CACHE_FILE = _find_first_existing(['ili_state_all.csv','ili_allstates.csv','ili_state_weekly.csv','ili_states_weekly.csv'],\n",
    "                                          search_dirs=('./cache','./cache/ili_cache_states','./cache/ili_cache'))\n",
    "ili_df=None\n",
    "if ILI_CACHE_FILE and os.path.exists(ILI_CACHE_FILE):\n",
    "    try:\n",
    "        ili_df = pd.read_csv(ILI_CACHE_FILE)\n",
    "        preview(ili_df,'ILI cache')\n",
    "    except Exception as e:\n",
    "        print('[warn] ILI load failed:', e)\n",
    "else:\n",
    "    print('[info] No ILI cache file found (OK).')\n",
    "\n",
    "# GT\n",
    "if GT_CACHE_DIR is None:\n",
    "    for cand in ['./gt_cache_states','./gt_cache','./cache/gt_cache_states']:\n",
    "        if os.path.isdir(cand):\n",
    "            GT_CACHE_DIR = cand; break\n",
    "if GT_CACHE_DIR and os.path.isdir(GT_CACHE_DIR):\n",
    "    hits = glob.glob(os.path.join(GT_CACHE_DIR, '*.csv')) or glob.glob(os.path.join(GT_CACHE_DIR, '**','*.csv'), recursive=True)\n",
    "    hits = hits[:3]\n",
    "    print(f'[info] GT cache dir: {GT_CACHE_DIR} (showing up to 3)')\n",
    "    for h in hits:\n",
    "        try:\n",
    "            dfh = pd.read_csv(h, nrows=5)\n",
    "            print('  -', os.path.relpath(h))\n",
    "            display(dfh.head(3))\n",
    "        except Exception as e:\n",
    "            print('  - (read error)', h, e)\n",
    "else:\n",
    "    print('[info] No GT cache dir found (OK).')\n",
    "\n",
    "# Humidity\n",
    "if HUMIDITY_DAILY_CSV and os.path.exists(HUMIDITY_DAILY_CSV):\n",
    "    try:\n",
    "        hum = pd.read_csv(HUMIDITY_DAILY_CSV)\n",
    "        preview(hum, 'Humidity (daily)')\n",
    "    except Exception as e:\n",
    "        print('[warn] Humidity load failed:', e)\n",
    "else:\n",
    "    print('[info] No humidity daily CSV specified (preview skipped).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e22839f",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Mobility + R(t) loaders (auto-detect with fallbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1446fef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mobility\n",
    "if MOBILITY_CSV is None:\n",
    "    MOBILITY_CSV = _find_first_existing(['mobility_state_weekly.csv','mobility_state_weekly_pct.csv','mobility_pct_weekly.csv'],\n",
    "                                        search_dirs=('./cache','./outputs','./'))\n",
    "print('Mobility path:', MOBILITY_CSV)\n",
    "assert MOBILITY_CSV is not None, 'Mobility CSV not found. Set MOBILITY_CSV.'\n",
    "\n",
    "# R(t)\n",
    "if RT_CSV is None:\n",
    "    RT_CSV = _find_first_existing(['rt_state_weekly.csv','rt_weekly_allstates.csv','rt_allstates_weekly.csv','Rt_weekly_allstates.csv'],\n",
    "                                  search_dirs=('./cache','./outputs','./'))\n",
    "if RT_CSV is None:\n",
    "    cand=None\n",
    "    for pat in ['./outputs/fig2/Fig2_weekly_scatter_inputs.csv','./**/Fig2_weekly_scatter_inputs.csv']:\n",
    "        hits=_case_insensitive_glob(pat)\n",
    "        if hits: cand=hits[0]; break\n",
    "    if cand is not None:\n",
    "        print('[fallback] Found Fig2_weekly_scatter_inputs at:', cand)\n",
    "        df_src=pd.read_csv(cand)\n",
    "        df_src.columns=[c.strip().lower() for c in df_src.columns]\n",
    "        def _pick_state_col(cols):\n",
    "            for n in ['state','state_abbr','st','state_code','stateid','state_id']:\n",
    "                if n in cols: return n\n",
    "            return None\n",
    "        def _pick_date_col(df):\n",
    "            hints=[c for c in df.columns if any(k in c for k in ['date','week','ending'])]\n",
    "            for c in hints:\n",
    "                try:\n",
    "                    pd.to_datetime(df[c]); return c\n",
    "                except Exception: pass\n",
    "            for c in df.columns:\n",
    "                s=pd.to_datetime(df[c], errors='coerce')\n",
    "                if s.notna().mean()>0.8: return c\n",
    "            return None\n",
    "        def _pick_rt_col(df):\n",
    "            for n in ['rt','r_t','r','re','r_eff','r_effective','rt_weekly','rt_median']:\n",
    "                if n in df.columns: return n\n",
    "            num_cols=[c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "            best=None; best_score=-1\n",
    "            for c in num_cols:\n",
    "                s=pd.to_numeric(df[c], errors='coerce'); s=s[np.isfinite(s)]\n",
    "                if s.empty: continue\n",
    "                med=float(np.nanmedian(s)); std=float(np.nanstd(s))\n",
    "                score=0\n",
    "                if 0.5<=med<=2.0: score+=2\n",
    "                if 0.01<=std<=0.5: score+=1\n",
    "                if score>best_score: best_score=score; best=c\n",
    "            return best\n",
    "        state_col=_pick_state_col(df_src.columns)\n",
    "        date_col=_pick_date_col(df_src)\n",
    "        rt_col=_pick_rt_col(df_src)\n",
    "        assert state_col and date_col and rt_col, f'Fallback file lacks required columns. Found -> state:{state_col}, date:{date_col}, rt:{rt_col}'\n",
    "        rt_only=df_src[[state_col,date_col,rt_col]].rename(columns={state_col:'state',date_col:'date',rt_col:'rt'})\n",
    "        os.makedirs('./cache', exist_ok=True)\n",
    "        RT_CSV='./cache/rt_state_weekly.csv'\n",
    "        rt_only.to_csv(RT_CSV, index=False)\n",
    "        print('[fallback] Wrote Rt-only file:', RT_CSV, 'rows:', len(rt_only))\n",
    "\n",
    "print('Final paths:\\n  MOBILITY_CSV:', MOBILITY_CSV, '\\n  RT_CSV:', RT_CSV)\n",
    "assert RT_CSV is not None, 'R(t) CSV not found.'\n",
    "\n",
    "mob=pd.read_csv(MOBILITY_CSV); rt=pd.read_csv(RT_CSV)\n",
    "mob.columns=[c.strip().lower() for c in mob.columns]\n",
    "rt.columns=[c.strip().lower() for c in rt.columns]\n",
    "\n",
    "def _coalesce(cols, names):\n",
    "    for n in names:\n",
    "        if n in cols: return n\n",
    "    return None\n",
    "\n",
    "state_col_m=_coalesce(mob.columns,['state','state_abbr','st'])\n",
    "date_col_m=_coalesce(mob.columns,['date','week','week_ending','week_ending_date'])\n",
    "\n",
    "# robust mobility picker\n",
    "import pandas as pd\n",
    "\n",
    "def _pick_mob_col(df, manual=None):\n",
    "    cols=list(df.columns)\n",
    "    if manual and manual in cols:\n",
    "        return manual\n",
    "    common=['mob_pct','mobility_pct','pct_mobility','pct_vs_baseline','pct_change','mobility_dow_baseline',\n",
    "            'percent_change','percent_change_from_baseline','pct','mobility','mob','value']\n",
    "    for n in common:\n",
    "        if n in cols: return n\n",
    "    for c in cols:\n",
    "        if re.search(r'(pct|percent).*base|mob', c):\n",
    "            return c\n",
    "    num=[c for c in cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    best=None; best_score=-1\n",
    "    for c in num:\n",
    "        s=pd.to_numeric(df[c], errors='coerce'); s=s[np.isfinite(s)]\n",
    "        if s.empty: continue\n",
    "        med=float(np.nanmedian(s)); std=float(np.nanstd(s))\n",
    "        score=0\n",
    "        if -200<=med<=200: score+=1\n",
    "        if -3<=med<=3: score+=1\n",
    "        if std>0: score+=0.1\n",
    "        if score>best_score: best_score=score; best=c\n",
    "    return best\n",
    "\n",
    "mob_col=_pick_mob_col(mob, MOBILITY_VALUE_COL)\n",
    "state_col_r=_coalesce(rt.columns,['state','state_abbr','st'])\n",
    "date_col_r=_coalesce(rt.columns,['date','week','week_ending','week_ending_date'])\n",
    "rt_col=_coalesce(rt.columns,['rt','r_t','r','re','r_eff'])\n",
    "\n",
    "missing=[]\n",
    "for need,nm in [(state_col_m,'mobility state'),(date_col_m,'mobility date'),(mob_col,'mobility value'),\n",
    "                (state_col_r,'rt state'),(date_col_r,'rt date'),(rt_col,'rt value')]:\n",
    "    if need is None: missing.append(nm)\n",
    "if missing:\n",
    "    print('Mobility columns present:', mob.columns.tolist())\n",
    "    print('Rt columns present:', rt.columns.tolist())\n",
    "    raise ValueError('Missing required columns: ' + ', '.join(missing))\n",
    "\n",
    "mob=mob.rename(columns={state_col_m:'state', date_col_m:'date', mob_col:'mob_pct'})\n",
    "rt =rt.rename(columns={state_col_r:'state',  date_col_r:'date',  rt_col:'rt'})\n",
    "\n",
    "mob['date']=pd.to_datetime(mob['date']); rt['date']=pd.to_datetime(rt['date'])\n",
    "if mob['mob_pct'].abs().max() <= 1.5:\n",
    "    mob['mob_pct'] = mob['mob_pct'] * 100.0\n",
    "\n",
    "df_weekly=(pd.merge(rt, mob, on=['state','date'], how='inner').sort_values(['state','date']).reset_index(drop=True))\n",
    "df_weekly['season']=df_weekly['date'].dt.to_period('W').apply(lambda p: week_to_season(p.start_time))\n",
    "print('Rows after merge:', len(df_weekly))\n",
    "display(df_weekly.head(8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30947285",
   "metadata": {},
   "source": [
    "\n",
    "## 4) EAKF/SIR hooks (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc82921",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EAKF_STATE_TRAJ = None\n",
    "PARAM_PRIORS    = None\n",
    "\n",
    "eakf_df=None\n",
    "if EAKF_STATE_TRAJ and os.path.exists(EAKF_STATE_TRAJ):\n",
    "    try:\n",
    "        eakf_df=pd.read_csv(EAKF_STATE_TRAJ, parse_dates=['date'])\n",
    "        preview(eakf_df,'EAKF state trajectory')\n",
    "    except Exception as e:\n",
    "        print('[warn] EAKF load failed:', e)\n",
    "else:\n",
    "    print('[info] No EAKF trajectory provided (optional).')\n",
    "\n",
    "priors_df=None\n",
    "if PARAM_PRIORS and os.path.exists(PARAM_PRIORS):\n",
    "    try:\n",
    "        priors_df=pd.read_csv(PARAM_PRIORS)\n",
    "        preview(priors_df,'Parameter priors (Shaman/Yang/Lipsitch)')\n",
    "    except Exception as e:\n",
    "        print('[warn] Priors load failed:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f53899",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_rt_vs_mobility_clean(state, rt_weekly, mob_weekly_pct, savepath, title_extra=\"\"):\n",
    "    df=(pd.concat({'rt': rt_weekly, 'mob': mob_weekly_pct}, axis=1).sort_index().dropna())\n",
    "    if df.empty:\n",
    "        print(f'[skip] {state}: no overlap after dropna()'); return\n",
    "    s=df.rolling(3, min_periods=1, center=True).mean()\n",
    "    fig, ax1 = plt.subplots(figsize=(8,4))\n",
    "    ax1.plot(s.index, s['rt'], color='tab:blue', lw=2.6, label='R(t)')\n",
    "    ax1.axhline(1.0, color='0.6', ls='--', lw=1)\n",
    "    ax1.set_ylabel('R(t)', color='tab:blue'); ax1.tick_params(axis='y', colors='tab:blue')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(s.index, s['mob'], color='tab:orange', lw=2.0, label='%Δ mobility (baseline DoW)')\n",
    "    ax2.axhline(0, color='0.6', ls='--', lw=1)\n",
    "    ax2.set_ylabel('Mobility (%Δ vs baseline)', color='tab:orange'); ax2.tick_params(axis='y', colors='tab:orange')\n",
    "    ax1.set_title(f'{state}: R(t) vs Mobility{(\" — \"+title_extra) if title_extra else \"\"}')\n",
    "    ax1.set_xlabel('Week')\n",
    "    h1,l1=ax1.get_legend_handles_labels(); h2,l2=ax2.get_legend_handles_labels()\n",
    "    ax1.legend(h1+h2,l1+l2,loc='upper left',frameon=False)\n",
    "    fig.tight_layout(); fig.savefig(savepath, dpi=300, bbox_inches='tight'); plt.close(fig)\n",
    "\n",
    "\n",
    "def build_state_summaries(df_weekly, mode='MEDMED', drop_covid=True):\n",
    "    d=df_weekly.copy()\n",
    "    if drop_covid:\n",
    "        d=d[~d['season'].astype(str).str.contains('2020-21')]\n",
    "    if mode.upper()=='MEDMED':\n",
    "        within=d.groupby(['state','season']).agg(rt_stat=('rt','median'), mob_stat=('mob_pct','median'))\n",
    "        across=within.groupby('state').agg(rt_val=('rt_stat','median'), mob_val=('mob_stat','median'), n_seasons=('rt_stat','size')).reset_index()\n",
    "    elif mode.upper()=='P90P90':\n",
    "        within=d.groupby(['state','season']).agg(rt_stat=('rt', lambda x: np.nanpercentile(x,90)),\n",
    "                                                mob_stat=('mob_pct', lambda x: np.nanpercentile(x,90)))\n",
    "        across=within.groupby('state').agg(rt_val=('rt_stat', lambda x: np.nanpercentile(x,90)),\n",
    "                                          mob_val=('mob_stat', lambda x: np.nanpercentile(x,90)),\n",
    "                                          n_seasons=('rt_stat','size')).reset_index()\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'MEDMED' or 'P90P90'\")\n",
    "    return across.dropna(subset=['rt_val','mob_val']).sort_values('state')\n",
    "\n",
    "\n",
    "def spearman_rho(x,y):\n",
    "    try:\n",
    "        from scipy.stats import spearmanr\n",
    "        rho,p=spearmanr(x,y,nan_policy='omit')\n",
    "    except Exception:\n",
    "        xr=pd.Series(x).rank(); yr=pd.Series(y).rank()\n",
    "        rho=float(np.corrcoef(xr,yr)[0,1]); p=np.nan\n",
    "    return rho,p\n",
    "\n",
    "\n",
    "def plot_state_scatter_simple(tbl, xlab, ylab, title, savepath, annotate=True, draw_fit=True, alpha=0.9):\n",
    "    if tbl.empty:\n",
    "        print('[warn] empty table passed to scatter:', savepath); return\n",
    "    x=tbl['mob_val'].values.astype(float); y=tbl['rt_val'].values.astype(float)\n",
    "    rho,p=spearman_rho(x,y)\n",
    "    fig,ax=plt.subplots(figsize=(7,6))\n",
    "    ax.scatter(x,y,s=45,alpha=alpha)\n",
    "    if draw_fit and len(x)>=2 and np.isfinite(x).all() and np.isfinite(y).all():\n",
    "        try:\n",
    "            m,b=np.polyfit(x,y,1)\n",
    "            xs=np.linspace(np.nanmin(x),np.nanmax(x),100)\n",
    "            ax.plot(xs,m*xs+b,lw=1.2,alpha=0.5)\n",
    "        except Exception: pass\n",
    "    ax.set_xlabel(xlab); ax.set_ylabel(ylab)\n",
    "    ax.set_title(f\"{title}\\nSpearman ρ={rho:.2f},  p={p:.3g}\")\n",
    "    ax.grid(True,alpha=0.25)\n",
    "    if annotate:\n",
    "        for _,r in tbl.iterrows():\n",
    "            ax.annotate(r['state'],(r['mob_val'],r['rt_val']),xytext=(4,2),textcoords='offset points',fontsize=8)\n",
    "    fig.tight_layout(); fig.savefig(savepath, dpi=300, bbox_inches='tight'); plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Figure 1\n",
    "states=sorted(df_weekly['state'].dropna().unique())\n",
    "count=0\n",
    "for st in states:\n",
    "    d=df_weekly[df_weekly['state']==st].set_index('date')\n",
    "    if d[['rt','mob_pct']].dropna().empty:\n",
    "        print(f'[skip] {st}: no overlapping data'); continue\n",
    "    out_png=os.path.join(OUT_DIR, f'fig1_{st}_rt_vs_mob.png')\n",
    "    plot_rt_vs_mobility_clean(st, d['rt'], d['mob_pct'], out_png)\n",
    "    count+=1\n",
    "print(f'[ok] Figure 1 panels saved: {count}  -> {OUT_DIR}')\n",
    "\n",
    "# Figure 2 (PRIMARY & APPENDIX)\n",
    "tbl_med=build_state_summaries(df_weekly,mode='MEDMED',drop_covid=True)\n",
    "plot_state_scatter_simple(tbl_med,\n",
    "    xlab='Mobility (%Δ vs baseline) — seasonal MEDIAN across seasons',\n",
    "    ylab='R(t) — seasonal MEDIAN across seasons',\n",
    "    title='States: R(t) (typical) vs Mobility (typical) — PRIMARY (excl. 2020–21)',\n",
    "    savepath=os.path.join(OUT_DIR,'fig2_primary_MEDMED.png'), annotate=True, draw_fit=True)\n",
    "\n",
    "tbl_p90=build_state_summaries(df_weekly,mode='P90P90',drop_covid=True)\n",
    "plot_state_scatter_simple(tbl_p90,\n",
    "    xlab='Mobility (%Δ vs baseline) — seasonal p90 across seasons',\n",
    "    ylab='R(t) — seasonal p90 across seasons',\n",
    "    title='States: R(t) (high) vs Mobility (high) — PRIMARY (excl. 2020–21)',\n",
    "    savepath=os.path.join(OUT_DIR,'fig2_primary_P90P90.png'), annotate=True, draw_fit=True)\n",
    "\n",
    "tbl_med_all=build_state_summaries(df_weekly,mode='MEDMED',drop_covid=False)\n",
    "plot_state_scatter_simple(tbl_med_all,\n",
    "    xlab='Mobility (%Δ vs baseline) — seasonal MEDIAN across seasons',\n",
    "    ylab='R(t) — seasonal MEDIAN across seasons',\n",
    "    title='States: R(t) (typical) vs Mobility (typical) — APPENDIX (incl. 2020–21)',\n",
    "    savepath=os.path.join(OUT_DIR,'figA_all_MEDMED.png'), annotate=True, draw_fit=True)\n",
    "\n",
    "tbl_p90_all=build_state_summaries(df_weekly,mode='P90P90',drop_covid=False)\n",
    "plot_state_scatter_simple(tbl_p90_all,\n",
    "    xlab='Mobility (%Δ vs baseline) — seasonal p90 across seasons',\n",
    "    ylab='R(t) — seasonal p90 across seasons',\n",
    "    title='States: R(t) (high) vs Mobility (high) — APPENDIX (incl. 2020–21)',\n",
    "    savepath=os.path.join(OUT_DIR,'figA_all_P90P90.png'), annotate=True, draw_fit=True)\n",
    "\n",
    "print('[ok] Figure 2 panels saved ->', OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c6c53a",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Run summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f260282",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "pngs=sorted(Path(OUT_DIR).glob('*.png'))\n",
    "print(f'PNG outputs in {OUT_DIR}:')\n",
    "for p in pngs: print(' -', p.name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
